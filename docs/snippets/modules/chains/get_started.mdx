#### 使用 `LLMChain`

`LLMChain` 是最基础的链式构建块。它接收一个提示模板，使用用户的输入格式化它，并从LLM返回响应。

要使用 `LLMChain`，首先创建一个提示模板。

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)
```

我们现在可以创建一个非常简单的链条，它将接收用户输入，将其格式化为提示信息，然后将其发送到LLM。


```python
from langchain.chains import LLMChain
chain = LLMChain(llm=llm, prompt=prompt)

# Run the chain only specifying the input variable.
print(chain.run("colorful socks"))
```

<CodeOutputBlock lang="python">

```
    Colorful Toes Co.
```

</CodeOutputBlock>

如果有多个变量，您可以使用字典一次性输入它们。


```python
prompt = PromptTemplate(
    input_variables=["company", "product"],
    template="What is a good name for {company} that makes {product}?",
)
chain = LLMChain(llm=llm, prompt=prompt)
print(chain.run({
    'company': "ABC Startup",
    'product': "colorful socks"
    }))
```

<CodeOutputBlock lang="python">

```
    Socktopia Colourful Creations.
```

</CodeOutputBlock>

您也可以在`LLMChain`中使用聊天模型：


```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
)
human_message_prompt = HumanMessagePromptTemplate(
        prompt=PromptTemplate(
            template="What is a good name for a company that makes {product}?",
            input_variables=["product"],
        )
    )
chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])
chat = ChatOpenAI(temperature=0.9)
chain = LLMChain(llm=chat, prompt=chat_prompt_template)
print(chain.run("colorful socks"))
```

<CodeOutputBlock lang="python">

```
    Rainbow Socks Co.
```

</CodeOutputBlock>
