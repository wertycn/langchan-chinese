# 缓存
LangChain为LLM提供了一个可选的缓存层。这有两个好处：

如果您经常多次请求相同的完成请求，它可以通过减少您对LLM提供程序的API调用次数来节省您的费用。
通过减少您对LLM提供程序的API调用次数，它可以加快您的应用程序的速度。

import CachingLLM from "@snippets/modules/model_io/models/llms/how_to/llm_caching.mdx"

<CachingLLM/>
