# PromptLayer

本页面介绍如何在LangChain中使用[PromptLayer](https://www.promptlayer.com)。
分为两个部分：安装和设置，以及特定的PromptLayer包装器的参考。

## 安装和设置

如果您想使用PromptLayer：
- 安装promptlayer Python库 `pip install promptlayer`
- 创建一个PromptLayer账户
- 创建一个API令牌，并将其设置为环境变量（`PROMPTLAYER_API_KEY`）

## 包装器

### LLM

存在一个PromptLayer OpenAI LLM封装，您可以通过以下方式进行访问
```python
from langchain.llms import PromptLayerOpenAI
```

在实例化LLM时，使用参数`pl_tags`来标记您的请求。
```python
from langchain.llms import PromptLayerOpenAI
llm = PromptLayerOpenAI(pl_tags=["langchain-requests", "chatbot"])
```

要获取PromptLayer请求的id，请在实例化LLM时使用参数`return_pl_id`。
```python
from langchain.llms import PromptLayerOpenAI
llm = PromptLayerOpenAI(return_pl_id=True)
```
这将在使用`.generate`或`.agenerate`时，将PromptLayer请求ID添加到返回的`Generation`的`generation_info`字段中。

例如：
```python
llm_results = llm.generate(["hello world"])
for res in llm_results.generations:
    print("pl request id: ", res[0].generation_info["pl_request_id"])
```
您可以使用PromptLayer请求ID来为您的请求添加提示、得分或其他元数据。[在此处阅读更多信息](https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9)。

该语言模型与[OpenAI LLM](./openai.md)完全相同，唯一的区别是：
- 您的所有请求都将被记录到您的PromptLayer账户中
- 您可以在实例化时添加`pl_tags`来对您的请求进行标记
- 在实例化时，您可以添加`return_pl_id`参数，以返回一个PromptLayer请求的ID，用于在跟踪请求时使用[（查看详细信息）](https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9)。

PromptLayer还提供了[`PromptLayerChatOpenAI`](/docs/modules/model_io/models/chat/integrations/promptlayer_chatopenai.html)和`PromptLayerOpenAIChat`的本地封装。
