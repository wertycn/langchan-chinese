# SageMaker终端节点

>[Amazon SageMaker](https://aws.amazon.com/sagemaker/)是一个可以构建、训练和部署机器学习（ML）模型的系统，具备完全托管的基础设施、工具和工作流程。

我们使用`SageMaker`来托管我们的模型，并将其作为`SageMaker终端节点`公开。

## 安装和设置

```bash
pip install boto3
```

有关如何将模型作为SageMaker端点公开的说明，请参阅[这里](https://www.philschmid.de/custom-inference-huggingface-sagemaker)。

**注意**：为了处理批量请求，我们需要在自定义的`inference.py`脚本中调整`predict_fn()`函数的返回行:

从

```
return {"vectors": sentence_embeddings[0].tolist()}
```

to:

```
return {"vectors": sentence_embeddings.tolist()}
```



我们必须设置`SagemakerEndpoint`调用的以下必需参数：
- `endpoint_name`：已部署的Sagemaker模型的端点名称。在AWS区域内必须是唯一的。
- `credentials_profile_name`：在~/.aws/credentials或~/.aws/config文件中的配置文件名称，其中包含访问密钥或角色信息。
    如果未指定，将使用默认凭证配置文件，或者在EC2实例上使用IMDS中的凭证。
    请参阅[此指南](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)。

## LLM

请参阅[用法示例](/docs/modules/model_io/models/llms/integrations/sagemaker.html)。

```python
from langchain import SagemakerEndpoint
from langchain.llms.sagemaker_endpoint import LLMContentHandler
```

## 文本嵌入模型

请查看[使用示例](/docs/modules/data_connection/text_embedding/integrations/sagemaker-endpoint.html)。
```python
from langchain.embeddings import SagemakerEndpointEmbeddings
from langchain.llms.sagemaker_endpoint import ContentHandlerBase
```
